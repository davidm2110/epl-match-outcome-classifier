{"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2687,"status":"ok","timestamp":1650911557676,"user":{"displayName":"David Murphy","userId":"13703184634524187557"},"user_tz":-60},"id":"0GKhDr6Vzfn_","outputId":"f47d032d-0a8d-4d2a-8b21-2bc58428cbd2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"YoWU0XMEzdII","executionInfo":{"status":"ok","timestamp":1650911558912,"user_tz":-60,"elapsed":9,"user":{"displayName":"David Murphy","userId":"13703184634524187557"}}},"outputs":[],"source":["import os\n","os.chdir(\"/content/gdrive/My Drive/\")"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"93iRYCWD14D6","executionInfo":{"status":"ok","timestamp":1650911559841,"user_tz":-60,"elapsed":937,"user":{"displayName":"David Murphy","userId":"13703184634524187557"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import glob\n","import datetime\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.svm import SVC\n","from sklearn.gaussian_process import GaussianProcessClassifier\n","from sklearn.gaussian_process.kernels import RBF\n","from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n","from sklearn.naive_bayes import GaussianNB, BernoulliNB\n","from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n","import re\n","from sklearn import preprocessing\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, classification_report, recall_score\n","import math\n","\n","from sklearn.inspection import permutation_importance\n","from sklearn.model_selection import GridSearchCV\n","\n","from sklearn.gaussian_process.kernels import RBF\n","from sklearn.gaussian_process.kernels import DotProduct\n","from sklearn.gaussian_process.kernels import Matern\n","from sklearn.gaussian_process.kernels import RationalQuadratic\n","from sklearn.gaussian_process.kernels import WhiteKernel\n","\n","from sklearn.compose import make_column_transformer\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n"]},{"cell_type":"markdown","source":["Create a dataset that each row calculates per team rather than just home and away e.g one big dataset but if home team = liverpool HWins10 will be the number of home wins for liverpool in the last 10."],"metadata":{"id":"VkxpGGTQX5du"}},{"cell_type":"code","execution_count":9,"metadata":{"id":"uUwYgRVVzaRx","colab":{"base_uri":"https://localhost:8080/","height":774},"executionInfo":{"status":"ok","timestamp":1650912961167,"user_tz":-60,"elapsed":779860,"user":{"displayName":"David Murphy","userId":"13703184634524187557"}},"outputId":"e8344ed6-d3ca-49b0-d284-35542b9cb084"},"outputs":[{"output_type":"stream","name":"stdout","text":["\\begin{tabular}{lllll}\n","\\toprule\n","               Classifiers & F1-Scores & Accuracy & Precision & Recall \\\\\n","\\midrule\n","GradientBoostingClassifier &      0.78 &   80.25\\% &    78.46\\% &  77.8\\% \\\\\n","                  AdaBoost &      0.75 &   77.52\\% &     75.5\\% & 75.06\\% \\\\\n","          Gaussian Process &      0.72 &   74.66\\% &    72.57\\% & 71.37\\% \\\\\n","LinearDiscriminantAnalysis &      0.71 &   73.66\\% &    71.32\\% & 71.04\\% \\\\\n","                       SVM &       0.7 &   74.16\\% &    72.28\\% &  69.9\\% \\\\\n","                Neural Net &      0.69 &    71.8\\% &    70.73\\% & 67.97\\% \\\\\n","                       QDA &      0.67 &   70.68\\% &    68.38\\% & 66.39\\% \\\\\n","             Decision Tree &      0.65 &   67.33\\% &    65.03\\% & 65.15\\% \\\\\n","             Random Forest &      0.61 &   66.34\\% &    67.59\\% & 60.11\\% \\\\\n","      ExtraTreesClassifier &       0.6 &   62.73\\% &    60.21\\% & 60.19\\% \\\\\n","         Nearest Neighbors &      0.51 &   53.42\\% &    50.58\\% & 50.86\\% \\\\\n","               Naive Bayes &      0.48 &   62.24\\% &    76.81\\% & 52.46\\% \\\\\n","               BernoulliNB &      0.46 &   57.64\\% &    74.99\\% & 48.49\\% \\\\\n","\\bottomrule\n","\\end{tabular}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["                   Classifiers F1-Scores Accuracy Precision  Recall\n","9   GradientBoostingClassifier      0.78   80.25%    78.46%   77.8%\n","6                     AdaBoost      0.75   77.52%     75.5%  75.06%\n","2             Gaussian Process      0.72   74.66%    72.57%  71.37%\n","10  LinearDiscriminantAnalysis      0.71   73.66%    71.32%  71.04%\n","1                          SVM       0.7   74.16%    72.28%   69.9%\n","5                   Neural Net      0.69    71.8%    70.73%  67.97%\n","8                          QDA      0.67   70.68%    68.38%  66.39%\n","3                Decision Tree      0.65   67.33%    65.03%  65.15%\n","4                Random Forest      0.61   66.34%    67.59%  60.11%\n","11        ExtraTreesClassifier       0.6   62.73%    60.21%  60.19%\n","0            Nearest Neighbors      0.51   53.42%    50.58%  50.86%\n","7                  Naive Bayes      0.48   62.24%    76.81%  52.46%\n","12                 BernoulliNB      0.46   57.64%    74.99%  48.49%"],"text/html":["\n","  <div id=\"df-a5031f2d-dfab-4144-9acb-52d580104016\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Classifiers</th>\n","      <th>F1-Scores</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>9</th>\n","      <td>GradientBoostingClassifier</td>\n","      <td>0.78</td>\n","      <td>80.25%</td>\n","      <td>78.46%</td>\n","      <td>77.8%</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>AdaBoost</td>\n","      <td>0.75</td>\n","      <td>77.52%</td>\n","      <td>75.5%</td>\n","      <td>75.06%</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Gaussian Process</td>\n","      <td>0.72</td>\n","      <td>74.66%</td>\n","      <td>72.57%</td>\n","      <td>71.37%</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>LinearDiscriminantAnalysis</td>\n","      <td>0.71</td>\n","      <td>73.66%</td>\n","      <td>71.32%</td>\n","      <td>71.04%</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>SVM</td>\n","      <td>0.7</td>\n","      <td>74.16%</td>\n","      <td>72.28%</td>\n","      <td>69.9%</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Neural Net</td>\n","      <td>0.69</td>\n","      <td>71.8%</td>\n","      <td>70.73%</td>\n","      <td>67.97%</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>QDA</td>\n","      <td>0.67</td>\n","      <td>70.68%</td>\n","      <td>68.38%</td>\n","      <td>66.39%</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Decision Tree</td>\n","      <td>0.65</td>\n","      <td>67.33%</td>\n","      <td>65.03%</td>\n","      <td>65.15%</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Random Forest</td>\n","      <td>0.61</td>\n","      <td>66.34%</td>\n","      <td>67.59%</td>\n","      <td>60.11%</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>ExtraTreesClassifier</td>\n","      <td>0.6</td>\n","      <td>62.73%</td>\n","      <td>60.21%</td>\n","      <td>60.19%</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Nearest Neighbors</td>\n","      <td>0.51</td>\n","      <td>53.42%</td>\n","      <td>50.58%</td>\n","      <td>50.86%</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Naive Bayes</td>\n","      <td>0.48</td>\n","      <td>62.24%</td>\n","      <td>76.81%</td>\n","      <td>52.46%</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>BernoulliNB</td>\n","      <td>0.46</td>\n","      <td>57.64%</td>\n","      <td>74.99%</td>\n","      <td>48.49%</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5031f2d-dfab-4144-9acb-52d580104016')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a5031f2d-dfab-4144-9acb-52d580104016 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a5031f2d-dfab-4144-9acb-52d580104016');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["#Read all datasets .csv files into one pandas dataframe\n","path = r'/content/gdrive/My Drive/Datasets/' # use your path\n","all_files = glob.glob(path + \"/*.csv\")\n","li = []\n","for filename in all_files:\n","    df = pd.read_csv(filename, index_col=None, header=0)\n","    li.append(df)\n","\n","frame = pd.concat(li, axis=0, ignore_index=True)\n","\n","#Filter out the betting stats columns for now\n","#Filter out the in games stats like fouls and cards for now also\n","df = frame.loc[: , :\"Referee\"]\n","\n","#Encode the dataframe (possibly should just do separate labelencoders per string column)\n","le = preprocessing.LabelEncoder()\n","df[[\"HomeTeam\", \"AwayTeam\"]] = df[[\"HomeTeam\", \"AwayTeam\"]].apply(le.fit_transform)\n","\n","individual_team_df = df.copy()\n","\n","home_goals = []\n","away_goals = []\n","rivals_home = []\n","rivals_away = []\n","\n","for row_num, row in individual_team_df.iterrows():\n","  #calculate the rolling sum of the last 5 games to assess home and away scoring tendencies\n","  individual_team_df[\"HGS5\"] = individual_team_df.loc[individual_team_df['HomeTeam'] == row['HomeTeam']][\"FTHG\"].rolling(min_periods=1, window=5).sum()\n","  individual_team_df[\"AGS5\"] = individual_team_df.loc[individual_team_df['AwayTeam'] == row['AwayTeam']][\"FTAG\"].rolling(min_periods=1, window=5).sum()\n","  individual_team_df[\"RivalsHGS5\"] = individual_team_df.loc[(individual_team_df['AwayTeam'] == row['AwayTeam']) & (individual_team_df['HomeTeam'] == row['HomeTeam'])][\"FTHG\"].rolling(min_periods=1, window=5).sum()\n","  individual_team_df[\"RivalsAGS5\"] = individual_team_df.loc[(individual_team_df['AwayTeam'] == row['AwayTeam']) & (individual_team_df['HomeTeam'] == row['HomeTeam'])][\"FTAG\"].rolling(min_periods=1, window=5).sum()\n","\n","  home_goals.append(individual_team_df.loc[row_num,\"HGS5\"])\n","  away_goals.append(individual_team_df.loc[row_num,\"AGS5\"])\n","  rivals_home.append(individual_team_df.loc[row_num,\"RivalsHGS5\"])\n","  rivals_away.append(individual_team_df.loc[row_num,\"RivalsAGS5\"])\n","\n","individual_team_df['HGS5'] = home_goals\n","individual_team_df['AGS5'] = away_goals\n","individual_team_df['RivalsHGS5'] = rivals_home\n","individual_team_df['RivalsAGS5'] = rivals_away\n","\n","#Calculate the average goals scored by home and away in their last 5 games aswell as the last 5 times they played eachother\n","individual_team_df[\"AHGS5\"] = individual_team_df[\"HGS5\"]/5\n","individual_team_df[\"AAGS5\"] = individual_team_df[\"AGS5\"]/5\n","individual_team_df[\"ARivalsHGS5\"] = individual_team_df[\"RivalsHGS5\"]/5\n","individual_team_df[\"ARivalsAGS5\"] = individual_team_df[\"RivalsAGS5\"]/5\n","\n","#Calculate percentage home wins, draws and away wins in the last 5 games\n","individual_team_df[\"HWins5\"] = pd.get_dummies(individual_team_df[\"FTR\"]).rolling(min_periods=1, window=5).sum()[\"H\"]/5\n","individual_team_df[\"AWins5\"] = pd.get_dummies(individual_team_df[\"FTR\"]).rolling(min_periods=1, window=5).sum()[\"A\"]/5\n","individual_team_df[\"Draws5\"] = pd.get_dummies(individual_team_df[\"FTR\"]).rolling(min_periods=1, window=5).sum()[\"D\"]/5\n","\n","#Drop any rows that have a NaN value in it.\n","feature_set = individual_team_df.rename(columns={\"FTR\": \"Result\"})\n","feature_set = feature_set[[\"HomeTeam\", \"AwayTeam\",\"AHGS5\", \"AAGS5\",\"ARivalsHGS5\",\"ARivalsAGS5\", \"HWins5\",\"AWins5\",\"Draws5\", \"Result\"]]\n","feature_set = feature_set.dropna()\n","y = np.array(feature_set.loc[:, \"Result\"])\n","X = np.array(feature_set.loc[:,:\"Draws5\"])\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","# models to test\n","names = [\n","    \"Nearest Neighbors\",\n","    \"SVM\",\n","    \"Gaussian Process\",\n","    \"Decision Tree\",\n","    \"Random Forest\",\n","    \"Neural Net\",\n","    \"AdaBoost\",\n","    \"Naive Bayes\",\n","    \"QDA\",\n","    \"GradientBoostingClassifier\",\n","    \"LinearDiscriminantAnalysis\",\n","    \"ExtraTreesClassifier\",\n","    \"BernoulliNB\"\n","]\n","\n","#Parameters found by extracting best_params_ after GridSearchCV()\n","classifiers = [\n","    KNeighborsClassifier(),\n","    SVC(C=100, gamma=0.0001, kernel = 'rbf'),\n","    GaussianProcessClassifier(kernel = 1**2 * Matern(length_scale=1, nu=1.5)),\n","    DecisionTreeClassifier(criterion = 'gini', max_depth=None),\n","    RandomForestClassifier(criterion = 'entropy', max_depth=3, n_estimators=10, max_features='sqrt'),\n","    MLPClassifier(alpha=1, max_iter=1000),\n","    AdaBoostClassifier(),\n","    GaussianNB(var_smoothing = 0.01),\n","    QuadraticDiscriminantAnalysis(reg_param = 0.1),\n","    GradientBoostingClassifier(),\n","    LinearDiscriminantAnalysis(),\n","    ExtraTreeClassifier(),\n","    BernoulliNB()\n","]\n","f1_scores = []\n","accuracies = []\n","precisions = []\n","recalls = []\n","for name, clf in zip(names, classifiers):\n","  clf.fit(X_train, y_train)\n","  prediction = clf.predict(X_test)\n","  f1_scores.append(\"{}\".format(round(f1_score(y_test, prediction, average=\"macro\"),2)))\n","  accuracies.append(\"{}%\".format(round(accuracy_score(y_test, prediction)*100,2)))\n","  precisions.append(\"{}%\".format(round(precision_score(y_test, prediction, average=\"macro\")*100,2)))\n","  recalls.append(\"{}%\".format(round(recall_score(y_test, prediction, average=\"macro\")*100,2)))\n","scores_dataframe = pd.DataFrame({'Classifiers': names, 'F1-Scores': f1_scores, 'Accuracy': accuracies, 'Precision': precisions, 'Recall': recalls}).sort_values(by=[\"F1-Scores\"], ascending=False)\n","scores_dataframe = scores_dataframe.sort_values(by=[\"F1-Scores\"], ascending = False)\n","print(scores_dataframe.to_latex(index=False))\n","display(scores_dataframe) \n"]},{"cell_type":"code","source":["from sklearn.inspection import permutation_importance\n","my_model = AdaBoostClassifier().fit(X_train, y_train)\n","r = permutation_importance(my_model, X_test, y_test,\n","                            n_repeats=30,\n","                            random_state=0)\n","\n","for i in r.importances_mean.argsort()[::-1]:\n","    if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n","         print(f\"{feature_set.columns[i]:<8}\"\n","               f\"{r.importances_mean[i]:.3f}\"\n","               f\" +/- {r.importances_std[i]:.3f}\")"],"metadata":{"id":"bJSDbHxF8AQB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650913004143,"user_tz":-60,"elapsed":6304,"user":{"displayName":"David Murphy","userId":"13703184634524187557"}},"outputId":"8f96c5a9-6680-4c09-95b9-b01465996aac"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["ARivalsHGS50.170 +/- 0.012\n","ARivalsAGS50.156 +/- 0.011\n","AWins5  0.066 +/- 0.011\n","Draws5  0.053 +/- 0.010\n","HWins5  0.045 +/- 0.007\n","AAGS5   0.030 +/- 0.007\n","AHGS5   0.028 +/- 0.008\n"]}]},{"cell_type":"code","source":["#Read all datasets .csv files into one pandas dataframe\n","path = r'/content/gdrive/My Drive/Datasets/' # use your path\n","all_files = glob.glob(path + \"/*.csv\")\n","li = []\n","for filename in all_files:\n","    df = pd.read_csv(filename, index_col=None, header=0)\n","    li.append(df)\n","\n","frame = pd.concat(li, axis=0, ignore_index=True)\n","\n","#Filter out the betting stats columns for now\n","#Filter out the in games stats like fouls and cards for now also\n","df = frame.loc[: , :\"Referee\"]\n","\n","#Encode the dataframe (possibly should just do separate labelencoders per string column)\n","le = preprocessing.LabelEncoder()\n","df[[\"HomeTeam\", \"AwayTeam\"]] = df[[\"HomeTeam\", \"AwayTeam\"]].apply(le.fit_transform)\n","\n","individual_team_df = df.copy()\n","\n","home_goals = []\n","away_goals = []\n","rivals_home = []\n","rivals_away = []\n","\n","for row_num, row in individual_team_df.iterrows():\n","  #calculate the rolling sum of the last 5 games to assess home and away scoring tendencies\n","  individual_team_df[\"HGS5\"] = individual_team_df.loc[individual_team_df['HomeTeam'] == row['HomeTeam']][\"FTHG\"].rolling(min_periods=1, window=5).sum()\n","  individual_team_df[\"AGS5\"] = individual_team_df.loc[individual_team_df['AwayTeam'] == row['AwayTeam']][\"FTAG\"].rolling(min_periods=1, window=5).sum()\n","  individual_team_df[\"RivalsHGS5\"] = individual_team_df.loc[(individual_team_df['AwayTeam'] == row['AwayTeam']) & (individual_team_df['HomeTeam'] == row['HomeTeam'])][\"FTHG\"].rolling(min_periods=1, window=5).sum()\n","  individual_team_df[\"RivalsAGS5\"] = individual_team_df.loc[(individual_team_df['AwayTeam'] == row['AwayTeam']) & (individual_team_df['HomeTeam'] == row['HomeTeam'])][\"FTAG\"].rolling(min_periods=1, window=5).sum()\n","\n","  home_goals.append(individual_team_df.loc[row_num,\"HGS5\"])\n","  away_goals.append(individual_team_df.loc[row_num,\"AGS5\"])\n","  rivals_home.append(individual_team_df.loc[row_num,\"RivalsHGS5\"])\n","  rivals_away.append(individual_team_df.loc[row_num,\"RivalsAGS5\"])\n","\n","individual_team_df['HGS5'] = home_goals\n","individual_team_df['AGS5'] = away_goals\n","individual_team_df['RivalsHGS5'] = rivals_home\n","individual_team_df['RivalsAGS5'] = rivals_away\n","\n","#Calculate the average goals scored by home and away in their last 5 games aswell as the last 5 times they played eachother\n","individual_team_df[\"AHGS5\"] = individual_team_df[\"HGS5\"]/5\n","individual_team_df[\"AAGS5\"] = individual_team_df[\"AGS5\"]/5\n","individual_team_df[\"ARivalsHGS5\"] = individual_team_df[\"RivalsHGS5\"]/5\n","individual_team_df[\"ARivalsAGS5\"] = individual_team_df[\"RivalsAGS5\"]/5\n","\n","#Calculate percentage home wins, draws and away wins in the last 5 games\n","individual_team_df[\"HWins5\"] = pd.get_dummies(individual_team_df[\"FTR\"]).rolling(min_periods=1, window=5).sum()[\"H\"]/5\n","individual_team_df[\"AWins5\"] = pd.get_dummies(individual_team_df[\"FTR\"]).rolling(min_periods=1, window=5).sum()[\"A\"]/5\n","individual_team_df[\"Draws5\"] = pd.get_dummies(individual_team_df[\"FTR\"]).rolling(min_periods=1, window=5).sum()[\"D\"]/5\n","\n","#Drop any rows that have a NaN value in it.\n","feature_set = individual_team_df.rename(columns={\"FTR\": \"Result\"})\n","feature_set = feature_set[[\"AHGS5\", \"AAGS5\", \"ARivalsHGS5\",\"ARivalsAGS5\", \"HWins5\",\"AWins5\",\"Draws5\", \"Result\"]]\n","feature_set = feature_set.dropna()\n","y = np.array(feature_set.loc[:, \"Result\"])\n","X = np.array(feature_set.loc[:,:\"Draws5\"])\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","# models to test\n","names = [\n","    \"Nearest Neighbors\",\n","    \"SVM\",\n","    \"Gaussian Process\",\n","    \"Decision Tree\",\n","    \"Random Forest\",\n","    \"Neural Net\",\n","    \"AdaBoost\",\n","    \"Naive Bayes\",\n","    \"QDA\",\n","    \"GradientBoostingClassifier\",\n","    \"LinearDiscriminantAnalysis\",\n","    \"ExtraTreesClassifier\",\n","    \"BernoulliNB\"\n","]\n","\n","#Parameters found by extracting best_params_ after GridSearchCV()\n","classifiers = [\n","    KNeighborsClassifier(),\n","    SVC(C=100, gamma=0.0001, kernel = 'rbf'),\n","    GaussianProcessClassifier(kernel = 1**2 * Matern(length_scale=1, nu=1.5)),\n","    DecisionTreeClassifier(criterion = 'gini', max_depth=None),\n","    RandomForestClassifier(criterion = 'entropy', max_depth=3, n_estimators=10, max_features='sqrt'),\n","    MLPClassifier(alpha=1, max_iter=1000),\n","    AdaBoostClassifier(),\n","    GaussianNB(var_smoothing = 0.01),\n","    QuadraticDiscriminantAnalysis(reg_param = 0.1),\n","    GradientBoostingClassifier(),\n","    LinearDiscriminantAnalysis(),\n","    ExtraTreeClassifier(),\n","    BernoulliNB()\n","]\n","\n","f1_scores = []\n","accuracies = []\n","precisions = []\n","recalls = []\n","for name, clf in zip(names, classifiers):\n","  clf.fit(X_train, y_train)\n","  prediction = clf.predict(X_test)\n","  f1_scores.append(\"{}\".format(round(f1_score(y_test, prediction, average=\"macro\"),2)))\n","  accuracies.append(\"{}%\".format(round(accuracy_score(y_test, prediction)*100,2)))\n","  precisions.append(\"{}%\".format(round(precision_score(y_test, prediction, average=\"macro\")*100,2)))\n","  recalls.append(\"{}%\".format(round(recall_score(y_test, prediction, average=\"macro\")*100,2)))\n","scores_dataframe = pd.DataFrame({'Classifiers': names, 'F1-Scores': f1_scores, 'Accuracy': accuracies, 'Precision': precisions, 'Recall': recalls})\n","scores_dataframe = scores_dataframe.sort_values(by=[\"F1-Scores\"], ascending = False)\n","print(scores_dataframe.to_latex(index=False))\n","display(scores_dataframe) \n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":774},"id":"td2sLofB9Tcx","executionInfo":{"status":"ok","timestamp":1650913784331,"user_tz":-60,"elapsed":581435,"user":{"displayName":"David Murphy","userId":"13703184634524187557"}},"outputId":"639419b4-011e-43c8-e6b3-4e02976a34e8"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\\begin{tabular}{lllll}\n","\\toprule\n","               Classifiers & F1-Scores & Accuracy & Precision & Recall \\\\\n","\\midrule\n","GradientBoostingClassifier &      0.76 &   78.26\\% &    76.61\\% & 76.06\\% \\\\\n","          Gaussian Process &      0.75 &   77.27\\% &    75.68\\% &  74.7\\% \\\\\n","                  AdaBoost &      0.74 &    76.4\\% &    74.66\\% & 74.38\\% \\\\\n","                Neural Net &      0.71 &   74.66\\% &    73.23\\% &  71.3\\% \\\\\n","         Nearest Neighbors &       0.7 &    72.3\\% &    70.04\\% & 69.87\\% \\\\\n","LinearDiscriminantAnalysis &       0.7 &    72.3\\% &    70.18\\% & 69.42\\% \\\\\n","             Decision Tree &      0.68 &   69.57\\% &    67.58\\% &  68.1\\% \\\\\n","               Naive Bayes &      0.68 &   70.56\\% &    68.61\\% & 68.06\\% \\\\\n","                       SVM &      0.67 &   72.05\\% &    71.25\\% & 67.47\\% \\\\\n","                       QDA &      0.66 &   70.68\\% &    68.79\\% & 66.19\\% \\\\\n","      ExtraTreesClassifier &      0.62 &   64.97\\% &    62.23\\% & 62.44\\% \\\\\n","             Random Forest &       0.6 &   66.46\\% &    66.83\\% & 61.14\\% \\\\\n","               BernoulliNB &       0.4 &   54.91\\% &    75.31\\% & 43.92\\% \\\\\n","\\bottomrule\n","\\end{tabular}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["                   Classifiers F1-Scores Accuracy Precision  Recall\n","9   GradientBoostingClassifier      0.76   78.26%    76.61%  76.06%\n","2             Gaussian Process      0.75   77.27%    75.68%   74.7%\n","6                     AdaBoost      0.74    76.4%    74.66%  74.38%\n","5                   Neural Net      0.71   74.66%    73.23%   71.3%\n","0            Nearest Neighbors       0.7    72.3%    70.04%  69.87%\n","10  LinearDiscriminantAnalysis       0.7    72.3%    70.18%  69.42%\n","3                Decision Tree      0.68   69.57%    67.58%   68.1%\n","7                  Naive Bayes      0.68   70.56%    68.61%  68.06%\n","1                          SVM      0.67   72.05%    71.25%  67.47%\n","8                          QDA      0.66   70.68%    68.79%  66.19%\n","11        ExtraTreesClassifier      0.62   64.97%    62.23%  62.44%\n","4                Random Forest       0.6   66.46%    66.83%  61.14%\n","12                 BernoulliNB       0.4   54.91%    75.31%  43.92%"],"text/html":["\n","  <div id=\"df-e7f45da1-44e3-49fc-8895-2dd3b7bfa052\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Classifiers</th>\n","      <th>F1-Scores</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>9</th>\n","      <td>GradientBoostingClassifier</td>\n","      <td>0.76</td>\n","      <td>78.26%</td>\n","      <td>76.61%</td>\n","      <td>76.06%</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Gaussian Process</td>\n","      <td>0.75</td>\n","      <td>77.27%</td>\n","      <td>75.68%</td>\n","      <td>74.7%</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>AdaBoost</td>\n","      <td>0.74</td>\n","      <td>76.4%</td>\n","      <td>74.66%</td>\n","      <td>74.38%</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Neural Net</td>\n","      <td>0.71</td>\n","      <td>74.66%</td>\n","      <td>73.23%</td>\n","      <td>71.3%</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Nearest Neighbors</td>\n","      <td>0.7</td>\n","      <td>72.3%</td>\n","      <td>70.04%</td>\n","      <td>69.87%</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>LinearDiscriminantAnalysis</td>\n","      <td>0.7</td>\n","      <td>72.3%</td>\n","      <td>70.18%</td>\n","      <td>69.42%</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Decision Tree</td>\n","      <td>0.68</td>\n","      <td>69.57%</td>\n","      <td>67.58%</td>\n","      <td>68.1%</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Naive Bayes</td>\n","      <td>0.68</td>\n","      <td>70.56%</td>\n","      <td>68.61%</td>\n","      <td>68.06%</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>SVM</td>\n","      <td>0.67</td>\n","      <td>72.05%</td>\n","      <td>71.25%</td>\n","      <td>67.47%</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>QDA</td>\n","      <td>0.66</td>\n","      <td>70.68%</td>\n","      <td>68.79%</td>\n","      <td>66.19%</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>ExtraTreesClassifier</td>\n","      <td>0.62</td>\n","      <td>64.97%</td>\n","      <td>62.23%</td>\n","      <td>62.44%</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Random Forest</td>\n","      <td>0.6</td>\n","      <td>66.46%</td>\n","      <td>66.83%</td>\n","      <td>61.14%</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>BernoulliNB</td>\n","      <td>0.4</td>\n","      <td>54.91%</td>\n","      <td>75.31%</td>\n","      <td>43.92%</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7f45da1-44e3-49fc-8895-2dd3b7bfa052')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e7f45da1-44e3-49fc-8895-2dd3b7bfa052 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e7f45da1-44e3-49fc-8895-2dd3b7bfa052');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"markdown","source":["We can remove HomeTeam and AwayTeam Features from the feature set based on this feature importance. When we do this I see an increase in performance in all models. AdaBoostClassifier is still the best achieving an accuracy score of ~76% and an F1-score increases from 0.69 to ~0.73. The GaussianProcessClassifier achieves an accuracy score of ~77% and also increases it's F1-score to ~0.75. MLPClassifier also saw an increase to 0.73 for F1-Score and ~77% for accuracy score.\n"],"metadata":{"id":"g5GZQ9JU9AdS"}},{"cell_type":"markdown","source":["Other models to note massive improvement in after this feature selection step is the KNearestNeighbor model and the Naive Bayes model where we see an increase of ~0.12 and ~0.19 in their respective F1-scores to. While the rest of the models show an increase of ~0.05 in F1-score."],"metadata":{"id":"v88meqlr_6T2"}},{"cell_type":"markdown","source":["**Below is commented out code if I want to change the feature calculation of Home Wins, Away Wins and Draws. After testing I get more or less the same results as without this and using the above code instead.**"],"metadata":{"id":"tfx_0jAITGar"}},{"cell_type":"code","source":["\"\"\"for row_num, row in individual_team_df.iterrows():\n","  #calculate the rolling sum of the last 5 games to assess home and away scoring tendencies\n","  individual_team_df[\"HGS5\"] = individual_team_df.loc[individual_team_df['HomeTeam'] == row['HomeTeam']][\"FTHG\"].rolling(min_periods=1, window=5).sum()\n","  individual_team_df[\"AGS5\"] = individual_team_df.loc[individual_team_df['AwayTeam'] == row['AwayTeam']][\"FTAG\"].rolling(min_periods=1, window=5).sum()\n","  individual_team_df[\"RivalsHGS5\"] = individual_team_df.loc[(individual_team_df['AwayTeam'] == row['AwayTeam']) & (individual_team_df['HomeTeam'] == row['HomeTeam'])][\"FTHG\"].rolling(min_periods=1, window=5).sum()\n","  individual_team_df[\"RivalsAGS5\"] = individual_team_df.loc[(individual_team_df['AwayTeam'] == row['AwayTeam']) & (individual_team_df['HomeTeam'] == row['HomeTeam'])][\"FTAG\"].rolling(min_periods=1, window=5).sum()\n","  \n","  #Calculate wins for home team while playing at home, wins for away team while playing away and draws in the last 5 games\n","  home_away_results = pd.get_dummies(individual_team_df.loc[individual_team_df['HomeTeam'] == row['HomeTeam']][\"FTR\"]).rolling(min_periods=1, window=5).sum()\n","  draw_results = pd.get_dummies(individual_team_df.loc[(individual_team_df['AwayTeam'] == row['AwayTeam']) | (individual_team_df['HomeTeam'] == row['HomeTeam'])][\"FTR\"]).rolling(min_periods=1, window=5).sum()\n","  if \"H\" in home_away_results.keys():\n","    individual_team_df[\"HWins5\"] = pd.get_dummies(individual_team_df.loc[individual_team_df['HomeTeam'] == row['HomeTeam']][\"FTR\"]).rolling(min_periods=1, window=5).sum()[\"H\"]/5\n","  else:\n","    individual_team_df[\"HWins5\"] = 0\n","  if \"A\" in home_away_results.keys():\n","    individual_team_df[\"AWins5\"] = pd.get_dummies(individual_team_df.loc[individual_team_df['AwayTeam'] == row['AwayTeam']][\"FTR\"]).rolling(min_periods=1, window=5).sum()[\"A\"]/5\n","  else:\n","    individual_team_df[\"AWins5\"] = 0\n","  if \"D\" in draw_results.keys():\n","    individual_team_df[\"Draws5\"] = pd.get_dummies(individual_team_df.loc[(individual_team_df['AwayTeam'] == row['AwayTeam']) | (individual_team_df['HomeTeam'] == row['HomeTeam'])][\"FTR\"]).rolling(min_periods=1, window=5).sum()[\"D\"]/5\n","  else:\n","    individual_team_df[\"Draws5\"] = 0\n","  \n","  home_goals.append(individual_team_df.loc[row_num,\"HGS5\"])\n","  away_goals.append(individual_team_df.loc[row_num,\"AGS5\"])\n","  rivals_home.append(individual_team_df.loc[row_num,\"RivalsHGS5\"])\n","  rivals_away.append(individual_team_df.loc[row_num,\"RivalsAGS5\"])\n","  home_wins.append(individual_team_df.loc[row_num,\"HWins5\"])\n","  away_wins.append(individual_team_df.loc[row_num,\"AWins5\"])\n","  draws.append(individual_team_df.loc[row_num,\"Draws5\"])\n","\n","individual_team_df['HGS5'] = home_goals\n","individual_team_df['AGS5'] = away_goals\n","individual_team_df['RivalsHGS5'] = rivals_home\n","individual_team_df['RivalsAGS5'] = rivals_away\n","individual_team_df['HWins5'] = home_wins\n","individual_team_df['AWins5'] = away_wins\n","individual_team_df['Draws5'] = draws\"\"\""],"metadata":{"id":"FOQctmk6ICgk"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"IndividualTeamModels_V2.ipynb","provenance":[],"authorship_tag":"ABX9TyMv/EQD0CMM3oWERVvLjmZP"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
